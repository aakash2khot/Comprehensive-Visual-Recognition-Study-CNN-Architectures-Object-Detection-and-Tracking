{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-22T08:56:21.932569Z","iopub.execute_input":"2023-03-22T08:56:21.933066Z","iopub.status.idle":"2023-03-22T08:56:21.951006Z","shell.execute_reply.started":"2023-03-22T08:56:21.933023Z","shell.execute_reply":"2023-03-22T08:56:21.949700Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"/kaggle/input/bikevshorse/bikeVShorse/Horses/horse1  (24).jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse68.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse75.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse57.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse36.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse67.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse12.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse59.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse38.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse33.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse81.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse29.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/h1.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse32.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse65.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse60.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse8 .jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse2 .jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse1  (12).jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse1  (37).jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse35.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse1  (33).jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse6 .jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse9 .jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse22.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse11.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse1  (8).jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse46.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse17.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse52.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse77.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse50.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse1  (44).jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse34.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse1  (32).jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse73.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse5 .jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse39.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse1  (5).jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse7 .jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse1  (6).jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse43.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse55.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse70.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse41.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse10.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse44.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse54.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse74.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse19.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse1 .jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse16.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse23.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse24.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse53.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse1  (7).jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse1  (17).jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse42.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse21.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse37.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse3 .jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse4 .jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse71.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse40.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse30.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse1  (26).jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse79.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse62.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/h2.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse64.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse72.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse56.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse1  (31).jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse1  (15).jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse51.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse14.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse76.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse28.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse58.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse1  (43).jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse47.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse20.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse45.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse18.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse78.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse1  (45).jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse26.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse66.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse48.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse49.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse63.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse25.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse15.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse80.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse31.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse69.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse61.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse13.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Horses/horse27.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0074.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0077.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0058.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0053.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0006.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0070.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0057.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0044.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0078.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0011.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0056.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0019.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0008.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0061.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0067.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0027.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0076.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0026.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0021.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0065.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0079.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0005.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0042.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0040.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0009.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0023.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0046.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0055.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0031.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0068.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0032.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0002.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0018.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0017.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0003.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0010.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0052.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0025.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0013.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0022.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0020.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0049.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0075.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0073.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0041.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0028.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0029.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0062.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0043.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0048.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0014.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0064.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0063.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0059.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0080.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0015.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0047.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0037.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0050.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0035.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0071.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0012.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0060.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0045.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0069.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0054.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0033.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0004.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0034.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0072.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0066.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0030.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0051.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0016.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0038.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0007.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0036.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0039.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0024.jpg\n/kaggle/input/bikevshorse/bikeVShorse/Bikes/0001.jpg\n","output_type":"stream"}]},{"cell_type":"code","source":"import torchvision.models as models\nimport torchvision.transforms as transforms\ntransform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])","metadata":{"execution":{"iopub.status.busy":"2023-03-22T08:56:21.953214Z","iopub.execute_input":"2023-03-22T08:56:21.954844Z","iopub.status.idle":"2023-03-22T08:56:21.961937Z","shell.execute_reply.started":"2023-03-22T08:56:21.954791Z","shell.execute_reply":"2023-03-22T08:56:21.960471Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"dataset = '../input/bikevshorse/bikeVShorse/'\nimport cv2\nfrom PIL import Image\n# Making Images and Labels for bike and Horse classification\nImages = []\nLabels = []\n\nClasses = [cls for cls in os.listdir(dataset) if os.path.isdir(os.path.join(dataset, cls))]\nh_b = 0\ncount=0\nfor cls in Classes:\n\n    dataset_Path = dataset+'/'+ cls\n    files = [f for f in os.listdir(dataset_Path) if os.path.isfile(os.path.join(dataset_Path, f))]\n    no_per_train=0\n    for i in files:\n        \n        img_path = dataset_Path+'/'+i\n        img = Image.open(img_path).convert('RGB')\n        image = transform(img)\n        Images.append(image)\n        Labels.append(h_b)\n        count=count+1\n        \n    h_b=h_b+1","metadata":{"execution":{"iopub.status.busy":"2023-03-22T08:56:21.963712Z","iopub.execute_input":"2023-03-22T08:56:21.964158Z","iopub.status.idle":"2023-03-22T08:56:23.551501Z","shell.execute_reply.started":"2023-03-22T08:56:21.964118Z","shell.execute_reply":"2023-03-22T08:56:23.550497Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport numpy as np\ntrain_Images,test_Images, train_Labels, test_Labels = train_test_split(Images, Labels, \n                                                train_size=0.8, random_state=42,shuffle = True,stratify = Labels)\n","metadata":{"execution":{"iopub.status.busy":"2023-03-22T08:56:23.553983Z","iopub.execute_input":"2023-03-22T08:56:23.554812Z","iopub.status.idle":"2023-03-22T08:56:23.570794Z","shell.execute_reply.started":"2023-03-22T08:56:23.554735Z","shell.execute_reply":"2023-03-22T08:56:23.569691Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Load pre-trained AlexNet model\nalexnet = models.alexnet(pretrained=True)\n\nfor param in alexnet.parameters():\n    param.requires_grad = False\nalexnet.classifier[6].requires_grad = True\n","metadata":{"execution":{"iopub.status.busy":"2023-03-22T08:56:23.572553Z","iopub.execute_input":"2023-03-22T08:56:23.573279Z","iopub.status.idle":"2023-03-22T08:56:24.519860Z","shell.execute_reply.started":"2023-03-22T08:56:23.573236Z","shell.execute_reply":"2023-03-22T08:56:24.518126Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n/opt/conda/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\ntrain_Images = torch.stack(train_Images)\ntest_Images = torch.stack(test_Images)\ntrain_features = alexnet.features(train_Images)\ntrain_features = train_features.view(train_features.size(0), -1).detach().numpy()\ntest_features = alexnet.features(test_Images)\ntest_features = test_features.view(test_features.size(0), -1).detach().numpy()","metadata":{"execution":{"iopub.status.busy":"2023-03-22T08:56:24.523696Z","iopub.execute_input":"2023-03-22T08:56:24.524367Z","iopub.status.idle":"2023-03-22T08:56:27.162938Z","shell.execute_reply.started":"2023-03-22T08:56:24.524290Z","shell.execute_reply":"2023-03-22T08:56:27.161802Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\n\nlogistic_regression = LogisticRegression()\nlogistic_regression.fit(train_features, train_Labels)\n\nfrom sklearn.metrics import accuracy_score\n\ny_pred = logistic_regression.predict(test_features)\ny_pred1 = logistic_regression.predict(train_features)\nprint(\"Training accuracy: \", accuracy_score(train_Labels,y_pred1))\nprint(\"Testing accuracy: \", accuracy_score(test_Labels,y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-03-22T08:56:27.164293Z","iopub.execute_input":"2023-03-22T08:56:27.167238Z","iopub.status.idle":"2023-03-22T08:56:27.422300Z","shell.execute_reply.started":"2023-03-22T08:56:27.167195Z","shell.execute_reply":"2023-03-22T08:56:27.420528Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Training accuracy:  1.0\nTesting accuracy:  1.0\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.svm import SVC\n\nsvc = SVC(kernel='linear')\nsvc.fit(train_features, train_Labels)\n\nfrom sklearn.metrics import accuracy_score\n\ny_pred = svc.predict(test_features)\ny_pred1 = svc.predict(train_features)\nprint(\"Training accuracy: \", accuracy_score(train_Labels,y_pred1))\nprint(\"Testing accuracy: \", accuracy_score(test_Labels,y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-03-22T08:56:27.424916Z","iopub.execute_input":"2023-03-22T08:56:27.426033Z","iopub.status.idle":"2023-03-22T08:56:27.551825Z","shell.execute_reply.started":"2023-03-22T08:56:27.425960Z","shell.execute_reply":"2023-03-22T08:56:27.549872Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Training accuracy:  1.0\nTesting accuracy:  1.0\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n\nmodel = GaussianNB()\n\nmodel.fit(train_features, train_Labels)\n\nfrom sklearn.metrics import accuracy_score\n\ny_pred = model.predict(test_features)\ny_pred1 = model.predict(train_features)\nprint(\"Training accuracy: \", accuracy_score(train_Labels,y_pred1))\nprint(\"Testing accuracy: \", accuracy_score(test_Labels,y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-03-22T08:56:27.553606Z","iopub.execute_input":"2023-03-22T08:56:27.554004Z","iopub.status.idle":"2023-03-22T08:56:27.590396Z","shell.execute_reply.started":"2023-03-22T08:56:27.553967Z","shell.execute_reply":"2023-03-22T08:56:27.589123Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Training accuracy:  1.0\nTesting accuracy:  0.75\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=2)\nknn.fit(train_features, train_Labels)\n\nfrom sklearn.metrics import accuracy_score\n\ny_pred = knn.predict(test_features)\ny_pred1 = knn.predict(train_features)\nprint(\"Training accuracy: \", accuracy_score(train_Labels,y_pred1))\nprint(\"Testing accuracy: \", accuracy_score(test_Labels,y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-03-22T08:57:56.951060Z","iopub.execute_input":"2023-03-22T08:57:56.952148Z","iopub.status.idle":"2023-03-22T08:57:57.019305Z","shell.execute_reply.started":"2023-03-22T08:57:56.952098Z","shell.execute_reply":"2023-03-22T08:57:57.018049Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Training accuracy:  0.986013986013986\nTesting accuracy:  1.0\n","output_type":"stream"}]}]}